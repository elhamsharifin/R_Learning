---
title: "Data_wrangling"
author: "Elham Sharifin, this course is taken from Edx data wrangling course. all the key points exactly the same of the course. I solved the questions myself!"
date: "4/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Key points: Introduction to wrnagling:
- The first step in data analysis is importing, tidying and cleaning the data. This is the process of data wrangling.

- Data analysis, for example checking correlations or creating visualizations, are done AFTER wrangling in which the data will be processed into a tidy format.

- In this course, we cover several common steps of the data wrangling process: tidying data, string processing, html parsing, working with dates and times, and text mining.

## Key points: Importing dat
- Many datasets are stored in spreadsheets. A spreadsheet is essentially a file version of a data frame with rows and columns.

- Spreadsheets have rows separated by returns and columns separated by a delimiter. The most common delimiters are comma, semicolon, white space and tab.

- Many spreadsheets are raw text files and can be read with any basic text editor. However, some formats are proprietary and cannot be read with a text editor, such as Microsoft Excel files (.xls).

- Most import functions assume that the first row of a spreadsheet file is a header with column names. To know if the file has a header, it helps to look at the file with a text editor before trying to import it.

## Key points: Paths and working directories:
- The working directory is where R looks for files and saves files by default.

- See your working directory with getwd(). Change your working directory with setwd().

- We suggest you create a directory for each project and keep your raw data inside that directory.

- Use the file.path() function to generate a full path from a relative path and a file name. Use file.path() instead of paste() because file.path() is aware of your operating system and will use the correct slashes to navigate your machine.

- The file.copy() function copies a file to a new path.
```{r}
#shows your working directory
getwd() 
```
```{r}
#changing the working directory
#setwd()
```
```{r}
# it shows the path of raw data inside the dslabs package and list files 
path <- system.file("extdata",package = "dslabs")
path 
list.files(path)
```
```{r}
# it will copy file from dslabs package to your working directory
filename <- "murders.csv"
fullpath <- file.path(path,filename)
file.copy(fullpath,getwd())
```
```{r}
#it shows if file exist in your working directory or not?
file.exists(filename)
```
```{r}
# copying the data murder.csv to an existing folder named data
getwd()
filename <- "murders.csv"
path <- system.file("extdata",package = "dslabs")
```
```{r}

# there are differnt ways for copying murders into data folder
## way1:
setwd("data")
file.copy(file.path(path, filename), getwd()) 
## way2:
file.copy(file.path(path, "murders.csv"), file.path(getwd(), "data"))
## way3:
file.location <- file.path(system.file("extdata", package = "dslabs"), "murders.csv")
file.destination <- file.path(getwd(), "data")
file.copy(file.location, file.destination) 

#way4: it does not work. it copies it into the parent directory
file.copy(file.path(path, "murders.csv"), getwd()) 
```

## Key points:The readr and readxl Packages
- readr is the tidyverse library that includes functions for reading data stored in text file spreadsheets into R. Functions in the package include:
read_csv(): comma seperated values, csv format
read_tsv(): tab delimited seperated values, tsv format
read_delim():general text file format,must define delimiter,txt format
read.csv2(): semicolon seperated values, csv format
read.table():white space seperated values, txt format
These differ by the delimiter they use to split columns.


- The readxl package provides functions to read Microsoft Excel formatted files.
read.excel: auto detect format. xlx, and xlsx formats
read.xls: original format (xls)
read.xlsx: new format, xlsx

- The excel_sheets() function gives the names of the sheets in the Excel file. These names are passed to the sheet argument for the readxl functions read_excel(), read_xls() and read_xlsx().

- The read_lines() function shows the first few lines of a file in R.

```{r}
library(dslabs)
library(tidyverse)    # includes readr
library(readxl)
```
```{r}
#it will investigate the first three lines
read_lines("murders.csv",n_max=3)
```
```{r}
#read files in csv format
dat <- read_csv(filename) #fiename from previous part
```
```{r}
# read file using fullpath
dat <- read_csv(fullpath) 
```
```{r}
head(dat)  #if we run in R console: we can see that file is a tibble
```
```{r}
#example: 
path <- system.file("extdata",package = "dslabs")
files <- list.files(path)
files

filename <- "murders.csv"
filename1 <- "life-expectancy-and-fertility-two-countries-example.csv"
filename2 <- "fertility-two-countries-example.csv"
dat <- read.csv(file.path(path,filename))
dat1 <- read.csv(file.path(path,filename1))
dat2 <- read.csv(file.path(path,filename2))

## excel files: suppose we have an excel file names times and the second sheet named 2016. we can read the second sheet with the following methos:
#times_2016 <- read_excel("times.xlsx", sheet = 2) 
#times_2016 <- read_excel("times.xlsx", sheet = "2016") 
```

## Key point: Importing Data Using R-base Functions
R-base import functions (read.csv(), read.table(), read.delim()) are different with read_... functions. R-base functions generate data frames rather than tibbles and character variables are converted to factors. This can be avoided by setting the argument stringsAsFactors=FALSE.
```{r}
filename <- "murders.csv"
dat2 <- read.csv(filename)
class(dat2)  #difference 1: we have data.frame not tibble
class(dat2$region) #character variables are converted to factors
```
```{r}
#converting to factors can be prevented by:
dat3 <- read.csv(filename,stringsAsFactors=FALSE)
class(dat3$region)
```

## Key points: Downloading Files from the Internet
- The read_csv() function and other import functions can read a URL directly.

- If there are no variable names in the first row fo a dataset, we have to add col_names=FALSE to skip putting the first row as header

- If you want to have a local copy of the file, you can use download.file().

- tempdir() creates a directory with a name that is very unlikely not to be unique.

- tempfile() creates a character string that is likely to be a unique filename.
```{r}
# reading data from internet
url <- "https://raw.githubusercontent.com/rafalab/dslabs/master/inst/extdata/murders.csv"
dat <- read_csv(url)
download.file(url,"murders.csv") #downloading file on your computer
tempfile() 
tmp_filename <- tempfile() #give a temporary name
download.file(url,tmp_filename)  #download it
file.remove(tmp_filename) #remove the temporary file
```
### Exercise: importing data
```{r}
library(tidyverse)
library(readr)

# import the file in the following url: http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data
url <- "http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
dat <- read_csv(url,col_names=FALSE) #very important, bcd there is no header for this data
ncol(dat)
nrow(dat)
```

## Key points: Tidy Data:
In tidy data, each row represents an observation and each column represents a different variable. very important!!!

In wide data, 1)each row includes several observations and 2)one of the variables is stored in the header.

```{r}
# Fertility data (example of tidy data)
library(tidyverse)
library(dslabs)
data(gapminder)
```
```{r}
# creating and investigating a tidy data frame
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
#plotting fertility vs. year
tidy_data %>%
  filter(!is.na(fertility),!is.na(year)) %>%
  ggplot(aes(year,fertility, color=country)) +
  geom_point()
```
```{r}
# import and investigate the original Gapminder data in wide format
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"fertility-two-countries-example.csv")
filename
file.copy(file.path(path, "fertility-two-countries-example.csv"), file.path(getwd(), "data"))
wide_data <- read_csv(filename) #same info but different format
select(wide_data, country, `1960`:`1967`)
```
 
## Key points: Reshaping data
- The tidyr package includes several functions that are useful for tidying data.

- The gather() function converts wide data into tidy data. gather takes 4 arguments: (1) the data, (2) the name of the key column, (3) the name of the value column, and optionally (4) the names of any columns not to gather

- The spread() function converts tidy data to wide data.

```{r}
## the original wide data
library(tidyverse) 
path <- system.file("extdata", package="dslabs")
filename <- file.path(path,  "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
```
```{r}
## tidy data from dslab package
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
## gather wide data to make new tidy data (way 1)
new_tidy_data <- wide_data %>%
  gather(year,fertility,'1960':'2015')
# This code will gather the years from 1960 to 2015 into a single column and create a single column called “fertility” that contains the fetrility rate for each country and each year.
head(new_tidy_data)
```
```{r}
## gather all columns except country (way 2)
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country)
head(new_tidy_data)
```
```{r}
class(tidy_data$year)
class(new_tidy_data$year)
# the gather function assumes that column name are charactor and we need to convert the column to numbers!
```
```{r}
## convert gathered column names to numeric:
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country,convert=TRUE)
head(new_tidy_data)

class(new_tidy_data$year)
```
```{r}
## now that the data are tidy, plotting
new_tidy_data %>%
  ggplot(aes(year,fertility,color=country)) +
  geom_point()
```
```{r}
## spread tidy data to generate wide data
new_wide_data <- new_tidy_data %>%
  spread(year,fertility)
select(new_wide_data, country, '1960':'1967')

```

## Key points: Separate and Unite
- The separate() function splits one column into two or more columns at a specified character that separates the variables. It has 3 argumnets: 1- the name of column to be seperated 2- the name to be used for the new column 3- charactor that seperates the variables

- When there is an extra separation in some of the entries, use fill="right" to pad missing values with NAs, or use extra="merge" to keep extra elements together.

- The unite() function combines two columns and adds a separating character.

1_Importing data:
```{r}
## Import data:
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"life-expectancy-and-fertility-two-countries-example.csv")
raw_data <- read_csv(filename)
select(raw_data,1:5)
```
2_gathering:
```{r}
## gather all columns but country
dat <- raw_data %>% gather(key,value,-country)
head(dat)
dat$key[1:5]
```
3_seperating:
```{r}
## seperate on underscores
dat %>% separate(key,c("year","variable_name"),"-")
dat %>% separate(key,c("year","variable_name"))
#error: it will seperate life_expectancy to two different parts and show only the first one
```
4_1: method 1 for tyding data:
```{r}
## way1_1: split on first underscore but keep life_expectancy merged 
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge")
```
```{r}
## way1_full code: seperate and then spread
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge") %>%
  spread("variable_name",value)
```
4_2: method 2 for tyding data (less efficient):
```{r}
## way2_1: split the variable to two different ones, NA(empty)
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right")
```
```{r}
## way2_2: seperate and then unite
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_")
```
```{r}
# way2_full code for tidying data (way2: using unite)
dat %>% 
  separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_") %>%
  spread(variable_name,value) %>%
  rename(fertility=fertility_NA)
```

### Exercise1 (Reshaping Data)
For the data names times.csv, tidy the data? 
and then return them to the wide data!
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times.csv")
x <- read_csv(filename)

## tidying data
tidy_data1 <- x %>% gather(year,time,'2015':'2017')

## converting to wide data again
tidy_data1 %>% spread(year,time)
# it will create new columns for every year and spread the time values over those cells
```

### Exercise 2: 
Suppose we have the US_disease data in the work directory, tydy the data in which all disease are put in one column.
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"US_disease.csv")
y <- read_csv(filename)

## tidying data:
tidy_data2 <- y %>% gather(key=disease,value,'HepatitisA':'Rubella')
```

### exercise 3: tidy data that population and total be in different columns? and change the name of column to population and total
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"Population.csv")
z <- read_csv(filename)

## tidying data:
tidy_data3 <- z %>% spread(key=var,value=people)
```
### Exercise 4: for the data of times2.csv in the working directory, in the best way tidy the data:
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times2.csv")
x4 <- read_csv(filename)

## tidying data
x4 %>% gather(key="key",value="value",-age_group) %>%
    separate(key,c("year","variable_name"), sep="_") %>%
  spread(variable_name,value)
```

### Exercise 5: tidy the dataset named basketbal with different columns for varaiables:
```{r}
## Import and read data:
path <- getwd()
filename <- file.path(path,"basketball.csv")
Q <- read_csv(filename)

## tidying data
Q %>%
  separate(key,c("name","variable_name"), sep="_",extra="merge") %>%
  spread(variable_name,value)
```

### Exercise 6: Consider dataset co2 which comes with basic R. 
This dataset is not tidy. becuase as seen, month is a variable and it should be in a column. also there are multiple observations in each wow. each observation should be different from another one. 
```{r}
## co2 concentration dataset:
library(tidyverse)
library(dslabs)
co2

co2_wide <- data.frame(matrix(co2,ncol=12,byrow=TRUE)) %>%
  setNames(1:12) %>% mutate(year=as.character(1959:1997))
co2_wide 

co2_tidy <- gather(co2_wide,month,co2,-year)
co2_tidy

co2_tidy %>% ggplot(aes(as.numeric(month),co2,color=year)) + geom_line()
```

### Exercise 7: for the data of admission on the dslabs package: 
```{r}
## tidy data which has one row for each major:
library(dslabs)
data(admissions)
head(admissions)

dat <- admissions %>% select(-applicants)
dat

dat %>% spread("gender",admitted)
```
```{r}
## using admission dataset, generate tmp which has major, gender, key and value as columns. 

tmp <- gather(admissions, key, value, admitted:applicants)
tmp

## create a column from joining gender and key:
tmp2 <- unite(tmp,column_name,c(key,gender))
tmp2
```

## Key points: combining tables
- The join functions in the dplyr package combine two tables such that matching rows are together.
- left_join() only keeps rows that have information in the first table.
- right_join() only keeps rows that have information in the second table.
- inner_join() only keeps rows that have information in both tables.
- full_join() keeps all rows from both tables.
- semi_join() keeps the part of first table for which we have information in the second.
- anti_join() keeps the elements of the first table for which there is no information in the second.

```{r}
## joining tables
library(tidyverse)
library(ggrepel)
library(dslabs)
ds_theme_set()

# importing murders data
data(murders)
head(murders)

#importing US election results
data(polls_us_election_2016)
head(results_us_election_2016)

#check whether two columns of state in the tables are identical to be joined or not?
identical(murders$state,results_us_election_2016$state)
```
```{r}
## joining two tables by left_joint:
tab <- left_join(murders,results_us_election_2016,by="state")
head(tab)
```
```{r}
## plotting US population vs. electral votes
tab %>% ggplot(aes(population,electoral_votes, label=abb)) +
  geom_point() +
  geom_text_repel() +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="log2") +
  geom_smooth(method="lm",se=FALSE)
```
```{r}
## joing two tables in which state contained in two tables are different
tab1 <- slice(murders,1:6) %>% select(state,population)
tab1

tab2 <- slice(results_us_election_2016,c(1,14,22,27,44:45)) %>%
  select(state,electoral_votes)
tab2
```
```{r}
#different ways of using left_joint:
left_join(tab1,tab2) #it will start from left (tab1)
tab1 %>% left_join(tab2) #it will start from left (tab1)
tab1 %>% right_join(tab2) #it will start from right (tab2)
inner_join(tab1,tab2) 
full_join(tab1,tab2) #it works as union function
semi_join(tab1,tab2) #it does not add the column from second table
anti_join(tab1,tab2) #it will keep the informaton of first table that they do not exist in the second one
```

## Key points: Binding
- Unlike the join functions, the binding functions do not try to match by a variable, but rather just combine datasets.

- bind_cols() binds two objects by making them columns in a tibble. The R-base function cbind() binds columns but makes a data frame or matrix instead.

- The bind_rows() function is similar but binds rows instead of columns. The R-base function rbind() binds rows but makes a data frame or matrix instead.

```{r}
## creating a dataset of numbers
bind_cols(a=1:3,b=4:6)
cbind(a=1:3,b=4:6) #it will create matrix and ...
```
```{r}
tab <- left_join(murders,results_us_election_2016,by="state")

tab1 <- tab[, 1:3]
tab2 <- tab[, 4:6]
tab3 <- tab[, 7:9]
new_tab <- bind_cols(tab1,tab2,tab3)
head(new_tab)
```
```{r}
tab1 <- tab[1:2,]
tab2 <- tab[3:4,]
bind_rows(tab1,tab2)
```

## Key points:set operators
- By default, the set operators in R-base work on vectors. If tidyverse/dplyr are loaded, they also work on data frames.

- You can take intersections of vectors using intersect(). This returns the elements common to both sets.

- You can take the union of vectors using union(). This returns the elements that are in either set.

- The set difference between a first and second argument can be obtained with setdiff(). Note that this function is not symmetric.

- The function set_equal() tells us if two sets are the same, regardless of the order of elements.

```{r}
## Intersect for vectors:
intersect(1:10,6:18)
intersect(c("a","b","c"),c("b","c","d"))
```
```{r}
## Intersect for data frames:
tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
intersect(tab1,tab2)
```
```{r}
## Union for vectors and data frames:
union(1:10,6:18)
union(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
union(tab1,tab2)
```
```{r}
## setdiff function 
setdiff(1:10,6:18) #it is not symmetric
setdiff(6:18,1:10)
setdiff(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setdiff(tab1,tab2)
```
```{r}
## setequal function
setequal(1:5,1:6)
setequal(1:5,5:1)

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setequal(tab1,tab2)
```

### Exercise 1: 
install Lahman library which is related to US profesional baseball. and load following datases: Batting, Master, Salaries, and AwardsPlayers tables.

Considering Batting dataset:
```{r}
#filter Batting dataset to define top as the top 10 home run (HR) hitters in 2016
library(Lahman)
#data(Batting)
top <- Batting %>% 
  filter(yearID == 2016) %>%
  arrange(desc(HR)) %>%    # arrange by descending HR count
  slice(1:10)    # take entries 1-10

top %>% as_tibble()
```
considering Master dataset:
```{r}
## considering Master dataset:
Master %>% as_tibble() #info about all players
```
Joining masters and Batting:
```{r}
# using differnt functions, show a final table including: player ID, first name, last name, and number of HR for the top 10 players
top_names <- top %>% left_join(Master) %>% select(playerID,nameFirst,nameLast,HR)
top_names
```
considering salaries dataframe and joing with top_names:
```{r}
#filter this data to year of 2016, and add a salary column to top_names and names the resulting data frame as top_salary.
library(Lahman)
#head(Salaries)
top_salaries <- Salaries %>% filter(yearID=="2016") %>%
  right_join(top_names) %>%
  select(nameFirst, nameLast, teamID, HR, salary)
top_salaries
```
considering AwardPlayers dataset:
```{r}
## considering AwardPlayers dataframe:
library(Lahman)
Award_players_2016 <- AwardsPlayers %>% filter(yearID=="2016")

## the number of top 10 players who won at least one award in 2016
length(intersect(Award_players_2016$playerID, top_names$playerID))
semi_join(top_names,Award_players_2016)

## the number of players who won an award but were not on top home hit runners in 2016
length(setdiff(Award_players_2016$playerID,top_names$playerID))
```

## Key points: Web Scrapping
- Web scraping is extracting data from a website.

- The rvest web harvesting package includes functions to extract nodes (<>) of an HTML document: html_nodes() extracts all nodes of different types, and html_node() extracts the first node.

- html_table() converts an HTML table to a data frame.
### importing webpage (murder) to R:
```{r}
# importing a webpage (murder) to R:
library(rvest)
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
h <- read_html(url)
class(h)
h  # we dont see very much!

tab <- h %>% html_nodes("table")

tab <- tab[[2]]

tab <- tab %>% html_table
class(tab)

tab <- tab %>% setNames(c("state", "population", "total", "murders", "gun_murders", "gun_ownership", "total_rate", "murder_rate", "gun_murder_rate"))
head(tab)
```
### importing webpage (corona virus) to R:
```{r}
# importing a webpage (corona virus statistics) to R:
library(rvest)
url <- "https://www.worldometers.info/coronavirus/"
h_corona <- read_html(url)
class(h_corona)

tab_corona <- h_corona %>% html_nodes("table")
tab_corona <- tab_corona[[2]]

tab_corona <- tab_corona%>% html_table
class(tab_corona)

```

## CSS Selector:
Here, we want to extract the recipe name, total preparation time, and list of ingredients from this guacamole recipe (https://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609). looking at the source page, it is very complex to determine the selector. SelectorGadget is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables, we highly recommend you install it. 
By installing SelectBudget, you can undestand the selectors:
```{r}
h <- read_html("https://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()

guacamole <- list(recipe,prep_time,ingredients)
guacamole

# creating a function from this recipe
get_recipe <- function(url){
  h <- read_html(url)
  recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
return(list(recipe,prep_time,ingredients))
}

# example of using the function get_recipe
get_recipe("https://www.foodnetwork.com/recipes/food-network-kitchen/pancakes-recipe-1913844")
```

There are several other powerful tools provided by rvest. For example, the functions html_form(), set_values(), and submit_form() permit you to query a webpage from R

### Exercise: Major League Baseballs Payrolls
use the following URL to access data related to Major League Baseball payrolls:
https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm
```{r}
library(rvest)
library(tidyverse)
h <- read_html("https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm")
nodes <- html_nodes(h,"table")
class(nodes) #html_nodes returns a list of objects of class xml_nodes

html_text(nodes[[8]]) #the content of each object can be seen by htm_text

html_table(nodes[[8]]) #convert the nodes (objects) to data.frame

## convert the first 4 tables to data.frame:
sapply(nodes[1:4],html_table)

## for the last three componenets of nodes:
html_table(nodes[[length(nodes)]])
html_table(nodes[[length(nodes)-1]])
html_table(nodes[[length(nodes)-2]])
```
```{r}
## for the nodes 9, 18: change table in which remove row1, and change the the column 1 of first table, and change the column names to Team, Payroll, and Average
###method 1 by Elham:
tab1 <- html_table(nodes[[9]]) %>% select(Team=X2,Payroll=X3,Average=X4) %>% slice(2:31)
head(tab1)
tab2 <- html_table(nodes[[18]]) %>% select(Team=X1,Payroll=X2,Average=X3) %>% slice(2:31)
head(tab2)
join_table <- full_join(tab1,tab2,by="Team")

### method 2 by Edx:
tab_1 <- html_table(nodes[[9]]) 
tab_2 <- html_table(nodes[[18]])

  #removing extra row and columns
tab_1 <- tab_1[-1,-1] #removing one row and one column from data frame
tab_2 <- tab_2[-1,]  #removing one raw from data frame.

  #changing the name of columns
column_name <- c("Team","Payroll","Average")
names(tab_1) <- column_name 
names(tab_2) <- column_name

full_join(tab1,tab2,by="Team")
```

### Exercise: 
following wikipedia page is related to polls of UK to leave the Europe Union in 2016. one of the tables show the results of all polls. 
https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054

```{r}
library(tidyverse)
library(rvest)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"

h <- read_html(url)
tab <- html_nodes(h,"table")
html_table(tab[[5]],fill=TRUE)

## what is the table number of the table "Date Conducted"?
html_table(tab[[5]],fill=TRUE) %>% names()
```

# 3_String Processing
## Key points: String Processing:
The most common tasks in string processing include:
- extracting numbers from strings
- removing unwanted characters from text
- finding and replacing characters
- extracting specific parts of strings
- converting free form text to more uniform formats
- splitting strings into multiple values
- The stringr package in the tidyverse contains string processing functions that follow a similar naming format (str_functionname) and are compatible with the pipe.

```{r}
library(tidyverse)
library(rvest)
## extracting murder data from wikipedia:
## table 2
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
murders_raw <- read_html(url) %>%
  html_nodes("table") %>%
  html_table()

murders_raw <- murders_raw[[2]] %>%
  setNames(c("state", "population", "total", "murders","gun_murders","gun_ownership","total_rate","murder_rate","gun_murder_rate"))
head(murders_raw)

#shorter methos!!!
murders_raw <- read_html(url) %>%
  html_nodes("table") %>%
  html_table() %>%
  .[[2]] %>%
  setNames(c("state", "population", "total", "murders","gun_murders","gun_ownership","total_rate","murder_rate","gun_murder_rate"))
head(murders_raw)


#specify the class of two columns which we expected to be numeric
class(murders_raw$total)
class(murders_raw$population)
# reason for that: for large numbers, ususlayy use , such as 2,50,000. and it results in assuming as charactor in web_scraping
  
```

## Key points: Defining Strings: Single and Double Quotes and How to Escape
- Define a string by surrounding text with either single quotes or double quotes.

- To include a single quote inside a string, use double quotes on the outside. To include a double quote inside a string, use single quotes on the outside.

- The cat() function displays a string as it is represented inside R.
To include a double quote inside of a string surrounded by double quotes, use the backslash (\) to escape the double quote. Escape a single quote to include it inside of a string defined by single quotes.

- We will see additional uses of the escape later.

```{r}
# strings
s <- "Hello" #defining string by double quotes
s1 <- 'Hello' #defining string by single quotes
#s <- `Hello` #backquoes gives error
class(s1)

s2 <- '5"' 
cat(s2)   #cat show what string looks like in the R

s3 <- "12'"
cat(s3)

# for including both sigle and double quotes in string, escape with \
#s4 <- '12'5"'    # error
#s4 <- "12'5""    # error
s4 <- '12\'5"'  
cat(s4)

s5 <- "12'5\""
cat(s5)

```

## Key points: stringr packages
- The main types of string processing tasks are detecting, locating, extracting and replacing elements of strings.

- The stringr package from the tidyverse includes a variety of string processing functions that begin with str_ and take the string as the first argument, which makes them compatible with the pipe.

```{r}
library(tidyverse)
library(rvest)
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
murders_raw <- read_html(url) %>%
  html_nodes("table") %>%
  html_table() %>%
  .[[2]] %>%
  setNames(c("state", "population", "total", "murders","gun_murders","gun_ownership","total_rate","murder_rate","gun_murder_rate"))
murders_raw$population[1:3]
as.numeric(murders_raw$population[1:3]) #it does not work because of camma
```

## Key points: Case Study, Murder data
- Use the str_detect() function to determine whether a string contains a certain pattern.
- Use the str_replace_all() function to replace all instances of one pattern with another pattern. To remove a pattern, replace with the empty string ("").
- The parse_number() function removes punctuation from strings and converts them to numeric.
- mutate_at() performs the same transformation on the specified column numbers.

```{r}
# extracting Murder data from Wikipedia
library(tidyverse)
library(rvest)
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
murders_raw <- read_html(url) %>%
  html_nodes("table") %>%
  html_table() %>%
  .[[2]] %>%
  setNames(c("state", "population", "total", "murders","gun_murders","gun_ownership","total_rate","murder_rate","gun_murder_rate"))

# detechting if there is any comma or not:
commas <- function(x) any(str_detect(x,","))
murders_raw %>% summarize_all(funs(commas))

#Replacing commas with space and converting to numeric values
test1 <- str_replace_all(murders_raw$population,",","")
class(test1)
test1 <- as.numeric(test1)
class(test1)

#using function parse_number for removing commas and converting to numeric
test2 <- parse_number(murders_raw$population)
identical(test1,test2) #they are not the same bcs of updated data and as.numeric does not work good because of inclusion of endnote links. later we will learn more

murders_new <- murders_raw %>% mutate_at(2:3,parse_number)
murders_new %>% head
```

### Exercise: for the "salary" dataset, convert string to numeric:

```{r}
library(tidyverse)
library(rvest)
path <- getwd()
#list.files(path)
filename <- file.path(path,"salary.csv")
salary <- read_csv(filename)

salary %>% mutate_at(2:3,parse_number) 
salary %>% mutate_at(2:3,funs(str_replace_all(., c("\\$|,"), ""))) %>%
  mutate_at(2:3,as.numeric)
salary %>% mutate_all(parse_number)  #incorrect, it will convert Month to numeric too
salary %>% mutate_at(2:3,as.numeric)  #incorrect, it gives NA because of comma
```

## Key points: Case Study 2: Reported Heights
- In the raw heights data, many students did not report their height as the number of inches as requested. There are many entries with real height information but in the wrong format, which we can extract with string processing. 

- When there are both text and numeric entries in a column, the column will be a character vector. Converting this column to numeric will result in NAs for some entries.

- To correct problematic entries, look for patterns that are shared across large numbers of entries, then define rules that identify those patterns and use these rules to write string processing tasks.

- Use suppressWarnings() to hide warning messages for a function.

```{r}
library(dslabs)
library(tidyverse)

#load raw data
data(reported_heights)
class(reported_heights$height) #because some students enter in other formats

#converting to numeric and counting NAs.
x <- as.numeric(reported_heights$height) #it create some NA
head(x)
sum(is.na(x)) #there are a lot of NA in the data

# shows entries resulting in NAs.
reported_heights %>% 
  mutate(new_height = as.numeric(height)) %>%
  filter(is.na(new_height)) %>%
  head(n=10)

```
```{r}
# # keep only entries that 1) result in NAs or 2) are outside the plausible range of heights
not_inches <- function(x,smallest=50,tallest=84){
  inches <- suppressWarnings(as.numeric(x))
  ind <- is.na(inches) | inches < smallest | inches > tallest
  ind
}
```
```{r}
# number of problematic entries
problems <- reported_heights %>%
  filter(not_inches(height)) %>% 
  .$height
length(problems)
```
```{r}
## the problematic entries are from 3 different groups:
# 10 examples of x'y or x'y" or x'y\"
pattern <- "^\\d\\s*'\\s*\\d{1,2}\\.*\\d*'*\"*$"
str_subset(problems, pattern) %>% head(n=10) %>% cat

# 10 examples of x.y or x,y
pattern <- "^[4-6]\\s*[\\.|,]\\s*([0-9]|10|11)$"
str_subset(problems, pattern) %>% head(n=10) %>% cat

# 10 examples of entries in cm rather than inches
ind <- which(between(suppressWarnings(as.numeric(problems))/2.54, 54, 81) )
ind <- ind[!is.na(ind)]
problems[ind] %>% head(n=10) %>% cat
```

### Pattern of string processing:
| or
\\d digit includinh(1:9)
^ = start of the string
[4-7] = one digit, either 4,5,6 or 7
' = feet symbol
\\d{1,2} = one or two digits
\" = inches symbol
$ = end of the string
\s=white space

^ = start of the string
[4-7] = one digit, either 4, 5, 6, or 7
\\s* = none or more white space
[,\\.\\s+] = feet symbol is either ,, . or at least one space
\\s* = none or more white space
\\d* = none or more digits
$ = end of the string

## Key points: Regular Expression
- A regular expression (regex) is a way to describe a specific pattern of characters of text. A set of rules has been designed to do this specifically and efficiently.

- stringr functions can take a regex as a pattern.

- str_detect() indicates whether a pattern is present in a string.

- The main difference between a regex and a regular string is that a regex can include special characters.

- The | symbol inside a regex means "or".

- Use '\\d' to represent digits. The backlash is used to distinguish it from the character 'd'. In R, you must use two backslashes for digits in regular expressions; in some other languages, you will only use one backslash for regex special characters.

- str_view() highlights the first occurrence of a pattern, and the str_view_all() function highlights all occurrences of the pattern.

```{r}
## loading stringr library through tidyverse
library(tidyverse)
library(rvest)

## loading data murders:
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
murders_raw <- read_html(url) %>%
  html_nodes("table") %>%
  html_table() %>%
  .[[2]] %>%
  setNames(c("state", "population", "total", "murders","gun_murders","gun_ownership","total_rate","murder_rate","gun_murder_rate"))

## detecting whether comma exists in the column or not?
pattern <- ","
str_detect(murders_raw$total,pattern)

## show subset of string including "," in the column (murder data)
str_subset(murders_raw$total,pattern)

## show subset of string including "cm" in the column (height data)
str_subset(reported_heights$height,"cm")
```

```{r}
## using | (or) inside the regex
yes <- c("180 cm","70 inches")
no <- c("180",'70"')
s <- c(yes,no)
str_detect(s,"cm") | str_detect(s, "inches")
str_detect(s,"cm|inches")  #easier way

str_view(s,"cm")
```
```{r}
## using \\d inside the regex
yes <- c("5","6","5'10","5 feet","4'11")
no <- c("",".","Five","six")
s <- c(yes,no)
pattern <- "\\d"
str_detect(s,pattern) #which of the strings has the pattern

## str_view: highlight the first occurrence of a pattern
#install.packages("htmlwidgets")
str_view(s,pattern)

## str_view_all: highlight all instances  of a pattern
str_view_all(s,pattern)
```

## Key points: Character Classes, Anchors and Quantifiers
- Define strings to test your regular expressions, including some elements that match and some that do not. This allows you to check for the two types of errors: failing to match and matching incorrectly.

- Square brackets define character classes: groups of characters that count as matching the pattern. You can use ranges to define character classes, such as [0-9] for digits and [a-zA-Z] for all letters. lowercase[a-z], uppercase[A-Z].
Be careful: at least (important) one lowercase letter [a-z]

-Note: [1-20]=0,1,2 ,it does not mean 1 to 20. it means charactor 1:2 and charactor 0. 

- Anchors define patterns that must start or end at specific places. ^ and $ represent the beginning and end of the string respectively. 
only one charactor:^\\d$

- Curly braces are quantifiers that state how many times a certain character can be repeated in the pattern. \\d{1,2} matches exactly 1 or 2 consecutive digits.

```{r}
yes <- c("5","6","5'10","5 feet","4'11")
no <- c("",".","Five","six")
s <- c(yes,no)

## [56] means 5 or 6
str_view(s,"[56]")

##[0-9] or \\d are the same
str_view(s,"[0-9]")
str_view_all(s,"[0-9]")
str_view(s,"[4-7]")
```
```{r}
## range of charactors
yes <- as.character(4:7)
no <- as.character(1:3)
s <- c(yes,no)
str_detect(s,"[4-7]")
```
```{r}
## ^ and $ mean start and end of string
pattern <- "^\\d$"
yes <- c("1","5","9")
no <- c("12","123"," 1","a4","b") #1 does not match bcs there is space before that
s <- c(yes,no)
str_view(s,pattern)
```
```{r}
## curly braces define quantifiers: 1 or 2 digits 
pattern <- "^\\d{1,2}$"
yes <- c("1","5","9")
no <- c("12","123"," 1","a4","b") 
s <- c(yes,no)
str_view(s,pattern)
```
```{r}
## pattern for inches and feet
pattern <- "^[4-7]'\\d{1,2}\"$"
# ^       start of string
#[4-7]    one digit 4,5,6, or 7
#'        the symbol of foot
#\\d{1,2} one or two digits
#\"       the inches symbol
#$        end of string

yes <- c("5'7\"", "6'2\"",  "5'12\"")
no <- c("6,2\"", "6.2\"","I am 5'11\"", "3'2\"", "64")
s <- c(yes,no)
str_detect(yes,pattern)
str_detect(no,pattern)
```

## Key points: Search adn Replace with Regex
- str_replace() replaces the first instance of the detected pattern with a specified string.

- Spaces are characters and R does not ignore them. Spaces are specified by the special character \\s.

- Additional quantifiers include *, + and ?. * means 0 or more instances of the previous character. ? means 0 or 1 instances. + means 1 or more instances.

- Before removing characters from strings with functions like str_replace() and str_replace_all(), consider whether that replacement would have unintended effects.

```{r}
#for the the height problem:
not_inches <- function(x,smallest=50,tallest=84){
  inches <- suppressWarnings(as.numeric(x))
  ind <- is.na(inches) | inches < smallest | inches > tallest
  ind
}

problems <- reported_heights %>%
  filter(not_inches(height)) %>% 
  .$height

## number of entries matching our desired pattern for the heights problem
pattern <- "^[4-7]'\\d{1,2}\"$"
sum(str_detect(problems,pattern))

## why only a few entries are selected for this pattern
problems[c(2,10,11,12,15)] %>% str_view(pattern)

## inspecting some examples of entries with problems
str_subset(problems,"inches")
str_subset(problems,"''")

## replacing or removing feet/inches words before matching
pattern <- "^[4-7]'\\d{1,2}$" #pattern withpour inches at the end
problems %>%
  str_replace("feet|ft|foot", "'") %>%
  str_replace("inches|inch|in|''|\"", "") %>%
  str_detect(pattern) %>%
  sum

## space are charactor and are not ignored by R
identical("Hi","Hi ")

## whitespace are specified with \\s
pattern2 <- "^[4-7]'\\s\\d{1,2}\"$"
str_subset(problems,pattern2)
```

```{r}
## explanation of * in regex:it means 0 or more instances of previouse charactor
yes <- c("AB", "A1B", "A11B", "A111B", "A1111B")
no <- c("A2B", "A21B")
str_detect(yes,"A1*B")
str_detect(no,"A1*B")

## (? : for none or one) (+ : for one or more)
data.frame(string=c("AB","A1B","A11B","A111B","A1111B"),
           none_or_more=str_detect(yes,"A1*B"),
           none_or_once=str_detect(yes,"A1?B"),
           once_or_more=str_detect(yes,"A1+B"))
```
```{r}
## backing to heights dataset:
pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
problems %>%
  str_replace("feet|ft|foot", "'") %>%
  str_replace("inches|inch|in|''|\"", "") %>%
  str_detect(pattern) %>%
  sum
```
###note: (str_replace_all())
we should not use function str_replace_all, becuase for the height dataset, some students enters 5 8, and if we remove space, it will be replaced by 58 that is incorect.

## Key Points: Group with regex
- Groups are defined using parentheses.

- Once we define groups, we can use the function str_match() to extract the values these groups define. str_extract() extracts only strings that match a pattern, not the values defined by groups.

- You can refer to the ith group with \\i. For example, refer to the value in the second group with \\2.

```{r}
## replacing x.y , x,y , x y to standard pattern of x'y
## define regix with and without group
pattern_without_group <- "^[4-7],\\d*$"
pattern_with_group <- "^([4-7]),(\\d*)$"

## example:
yes <- c("5,9", "5,11", "6,", "6,1")
no <- c("5'9", ",", "2,8", "6.1.1")
s <- c(yes,no)

## explaining the effect of group
str_detect(s,pattern_without_group)
str_detect(s,pattern_with_group) 
#Result;the parantheces do not change the matching processes

## explaining str_match and its difference with str_extract
str_match(s,pattern_with_group)
str_extract(s,pattern_with_group)

## improving the pattern to recognize more events
pattern_with_groups <-  "^([4-7]),(\\d*)$"
yes <- c("5,9", "5,11", "6,", "6,1")
no <- c("5'9", ",", "2,8", "6.1.1")
s <- c(yes, no)
str_replace(s,pattern_with_group,"\\1'\\2")
```

```{r}
#for height dataset:
pattern_with_group <- "^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$"
# explain: [,\\.\\s+] means comma,dot,or at least one space
#final pattern with considering group
str_subset(problems,pattern_with_group) %>% head

str_subset(problems,pattern_with_group) %>%
  str_replace(pattern_with_group,"\\1'\\2") %>% head()
```

## Key points: Testing and Improving
- Wrangling with regular expressions is often an iterative process of testing the approach, looking for problematic entries, and improving the patterns.

- Use the pipe to connect stringr functions.

- It may not be worth writing code to correct every unique problem in the data, but string processing techniques are flexible enough for most needs.

```{r}
## about the data of reported_heights
not_inches_or_cm <- function(x,smallest=50,tallest=84){
  inches <- suppressWarnings(as.numeric(x))
  ind <- !is.na(inches) &   #the entries that are not NA
    ((inches>=smallest & inches<=tallest) |
       (inches/2.54>=smallest & inches/2.54<=tallest))
  !ind  #everything except ind
}

## identify entries with problems
problems <- reported_heights %>%
  filter(not_inches_or_cm(height)) %>%
  .$height

length(problems)

converted <- problems %>%
    str_replace("feet|foot|ft", "'") %>%  #convert feet symbols to '
  str_replace("inches|in|''|\"", "") %>%  #remove inches symbols
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") ##change format

## finding the proportion of entries that fit the pattern after reformatting
pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
index <- str_detect(converted,pattern)
mean(index)

converted[!index]  #show the remained problems

```

```{r}
not_inches2 <- function(x, smallest = 50, tallest = 84) {
  inches <- suppressWarnings(as.numeric(x))
  ind <- is.na(inches) | inches < smallest | inches > tallest 
  ind
}
reported_heights$height[not_inches2(reported_heights$height)]
```

### Example:
```{r}
## differnt pattern for the following vector:
## Example1:
s <- c("70","5 ft","4'11","",".","Six feet")

pattern <- "\\d|ft" 
str_view_all(s,pattern)

pattern2 <- "\\d\\d|ft" 
str_view_all(s,pattern2)
```
```{r}
# Example2:
animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern3 <- "[a-z]"
str_detect(animals, pattern3)
```
```{r}
# Example3:
animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern4 <- "[A-Z]$" #it is looking for an uppercase at the end of string
str_detect(animals, pattern4)
```
```{r}
#Example4:
animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern5 <- "[a-z]{4,5}"
str_detect(animals, pattern5)
#looking for either 4 or 5 lowercase letters in a row anywhere in the string
```
```{r}
#Example5:
animals <- c("moose", "monkey", "meerkat", "mountain lion")
pattern6 <- "mo*"
str_detect(animals, pattern6)

pattern7 <- "mo?"
str_detect(animals, pattern7)

pattern8 <- "mo+"
str_detect(animals, pattern8)

pattern9 <- "moo*"
str_detect(animals, pattern9) #it will look for one m foloowed by zero, or more m
```
```{r}
schools <- c("U. Kentucky","Univ New Hampshire","Univ. of Massachusetts"    ,"University Georgia","U California","California State University")

## clean the above string and convert every university symbol to University
schools %>%
  str_replace("^(A-Z)\\.*(A-Z)$","")
```

