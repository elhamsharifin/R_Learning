---
title: "Data_wrangling"
author: "Elham Sharifin, this course is taken from Edx data wrangling course. all the key points exactly the same of the course. I solved the questions myself!"
date: "4/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Key points: Introduction to wrnagling:
- The first step in data analysis is importing, tidying and cleaning the data. This is the process of data wrangling.

- Data analysis, for example checking correlations or creating visualizations, are done AFTER wrangling in which the data will be processed into a tidy format.

- In this course, we cover several common steps of the data wrangling process: tidying data, string processing, html parsing, working with dates and times, and text mining.

## Key points: Importing dat
- Many datasets are stored in spreadsheets. A spreadsheet is essentially a file version of a data frame with rows and columns.

- Spreadsheets have rows separated by returns and columns separated by a delimiter. The most common delimiters are comma, semicolon, white space and tab.

- Many spreadsheets are raw text files and can be read with any basic text editor. However, some formats are proprietary and cannot be read with a text editor, such as Microsoft Excel files (.xls).

- Most import functions assume that the first row of a spreadsheet file is a header with column names. To know if the file has a header, it helps to look at the file with a text editor before trying to import it.

## Key points: Paths and working directories:
- The working directory is where R looks for files and saves files by default.

- See your working directory with getwd(). Change your working directory with setwd().

- We suggest you create a directory for each project and keep your raw data inside that directory.

- Use the file.path() function to generate a full path from a relative path and a file name. Use file.path() instead of paste() because file.path() is aware of your operating system and will use the correct slashes to navigate your machine.

- The file.copy() function copies a file to a new path.
```{r}
#shows your working directory
getwd() 
```
```{r}
#changing the working directory
#setwd()
```
```{r}
# it shows the path of raw data inside the dslabs package and list files 
path <- system.file("extdata",package = "dslabs")
path 
list.files(path)
```
```{r}
# it will copy file from dslabs package to your working directory
filename <- "murders.csv"
fullpath <- file.path(path,filename)
file.copy(fullpath,getwd())
```
```{r}
#it shows if file exist in your working directory or not?
file.exists(filename)
```
```{r}
# copying the data murder.csv to an existing folder named data
getwd()
filename <- "murders.csv"
path <- system.file("extdata",package = "dslabs")
```
```{r}

# there are differnt ways for copying murders into data folder
## way1:
setwd("data")
file.copy(file.path(path, filename), getwd()) 
## way2:
file.copy(file.path(path, "murders.csv"), file.path(getwd(), "data"))
## way3:
file.location <- file.path(system.file("extdata", package = "dslabs"), "murders.csv")
file.destination <- file.path(getwd(), "data")
file.copy(file.location, file.destination) 

#way4: it does not work. it copies it into the parent directory
file.copy(file.path(path, "murders.csv"), getwd()) 
```

## Key points:The readr and readxl Packages
- readr is the tidyverse library that includes functions for reading data stored in text file spreadsheets into R. Functions in the package include:
read_csv(): comma seperated values, csv format
read_tsv(): tab delimited seperated values, tsv format
read_delim():general text file format,must define delimiter,txt format
read.csv2(): semicolon seperated values, csv format
read.table():white space seperated values, txt format
These differ by the delimiter they use to split columns.


- The readxl package provides functions to read Microsoft Excel formatted files.
read.excel: auto detect format. xlx, and xlsx formats
read.xls: original format (xls)
read.xlsx: new format, xlsx

- The excel_sheets() function gives the names of the sheets in the Excel file. These names are passed to the sheet argument for the readxl functions read_excel(), read_xls() and read_xlsx().

- The read_lines() function shows the first few lines of a file in R.

```{r}
library(dslabs)
library(tidyverse)    # includes readr
library(readxl)
```
```{r}
#it will investigate the first three lines
read_lines("murders.csv",n_max=3)
```
```{r}
#read files in csv format
dat <- read_csv(filename) #fiename from previous part
```
```{r}
# read file using fullpath
dat <- read_csv(fullpath) 
```
```{r}
head(dat)  #if we run in R console: we can see that file is a tibble
```
```{r}
#example: 
path <- system.file("extdata",package = "dslabs")
files <- list.files(path)
files

filename <- "murders.csv"
filename1 <- "life-expectancy-and-fertility-two-countries-example.csv"
filename2 <- "fertility-two-countries-example.csv"
dat <- read.csv(file.path(path,filename))
dat1 <- read.csv(file.path(path,filename1))
dat2 <- read.csv(file.path(path,filename2))

## excel files: suppose we have an excel file names times and the second sheet named 2016. we can read the second sheet with the following methos:
#times_2016 <- read_excel("times.xlsx", sheet = 2) 
#times_2016 <- read_excel("times.xlsx", sheet = "2016") 
```

## Key point: Importing Data Using R-base Functions
R-base import functions (read.csv(), read.table(), read.delim()) are different with read_... functions. R-base functions generate data frames rather than tibbles and character variables are converted to factors. This can be avoided by setting the argument stringsAsFactors=FALSE.
```{r}
filename <- "murders.csv"
dat2 <- read.csv(filename)
class(dat2)  #difference 1: we have data.frame not tibble
class(dat2$region) #character variables are converted to factors
```
```{r}
#converting to factors can be prevented by:
dat3 <- read.csv(filename,stringsAsFactors=FALSE)
class(dat3$region)
```

## Key points: Downloading Files from the Internet
- The read_csv() function and other import functions can read a URL directly.

- If there are no variable names in the first row fo a dataset, we have to add col_names=FALSE to skip putting the first row as header

- If you want to have a local copy of the file, you can use download.file().

- tempdir() creates a directory with a name that is very unlikely not to be unique.

- tempfile() creates a character string that is likely to be a unique filename.
```{r}
# reading data from internet
url <- "https://raw.githubusercontent.com/rafalab/dslabs/master/inst/extdata/murders.csv"
dat <- read_csv(url)
download.file(url,"murders.csv") #downloading file on your computer
tempfile() 
tmp_filename <- tempfile() #give a temporary name
download.file(url,tmp_filename)  #download it
file.remove(tmp_filename) #remove the temporary file
```
### Exercise: importing data
```{r}
library(tidyverse)
library(readr)

# import the file in the following url: http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data
url <- "http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
dat <- read_csv(url,col_names=FALSE) #very important, bcd there is no header for this data
ncol(dat)
nrow(dat)
```

## Key points: Tidy Data:
In tidy data, each row represents an observation and each column represents a different variable. very important!!!

In wide data, 1)each row includes several observations and 2)one of the variables is stored in the header.

```{r}
# Fertility data (example of tidy data)
library(tidyverse)
library(dslabs)
data(gapminder)
```
```{r}
# creating and investigating a tidy data frame
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
#plotting fertility vs. year
tidy_data %>%
  filter(!is.na(fertility),!is.na(year)) %>%
  ggplot(aes(year,fertility, color=country)) +
  geom_point()
```
```{r}
# import and investigate the original Gapminder data in wide format
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"fertility-two-countries-example.csv")
filename
file.copy(file.path(path, "fertility-two-countries-example.csv"), file.path(getwd(), "data"))
wide_data <- read_csv(filename) #same info but different format
select(wide_data, country, `1960`:`1967`)
```
 
## Key points: Reshaping data
- The tidyr package includes several functions that are useful for tidying data.

- The gather() function converts wide data into tidy data. gather takes 4 arguments: (1) the data, (2) the name of the key column, (3) the name of the value column, and optionally (4) the names of any columns not to gather

- The spread() function converts tidy data to wide data.

```{r}
## the original wide data
library(tidyverse) 
path <- system.file("extdata", package="dslabs")
filename <- file.path(path,  "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
```
```{r}
## tidy data from dslab package
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
## gather wide data to make new tidy data (way 1)
new_tidy_data <- wide_data %>%
  gather(year,fertility,'1960':'2015')
# This code will gather the years from 1960 to 2015 into a single column and create a single column called “fertility” that contains the fetrility rate for each country and each year.
head(new_tidy_data)
```
```{r}
## gather all columns except country (way 2)
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country)
head(new_tidy_data)
```
```{r}
class(tidy_data$year)
class(new_tidy_data$year)
# the gather function assumes that column name are charactor and we need to convert the column to numbers!
```
```{r}
## convert gathered column names to numeric:
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country,convert=TRUE)
head(new_tidy_data)

class(new_tidy_data$year)
```
```{r}
## now that the data are tidy, plotting
new_tidy_data %>%
  ggplot(aes(year,fertility,color=country)) +
  geom_point()
```
```{r}
## spread tidy data to generate wide data
new_wide_data <- new_tidy_data %>%
  spread(year,fertility)
select(new_wide_data, country, '1960':'1967')

```

## Key points: Separate and Unite
- The separate() function splits one column into two or more columns at a specified character that separates the variables. It has 3 argumnets: 1- the name of column to be seperated 2- the name to be used for the new column 3- charactor that seperates the variables

- When there is an extra separation in some of the entries, use fill="right" to pad missing values with NAs, or use extra="merge" to keep extra elements together.

- The unite() function combines two columns and adds a separating character.

1_Importing data:
```{r}
## Import data:
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"life-expectancy-and-fertility-two-countries-example.csv")
raw_data <- read_csv(filename)
select(raw_data,1:5)
```
2_gathering:
```{r}
## gather all columns but country
dat <- raw_data %>% gather(key,value,-country)
head(dat)
dat$key[1:5]
```
3_seperating:
```{r}
## seperate on underscores
dat %>% separate(key,c("year","variable_name"),"-")
dat %>% separate(key,c("year","variable_name"))
#error: it will seperate life_expectancy to two different parts and show only the first one
```
4_1: method 1 for tyding data:
```{r}
## way1_1: split on first underscore but keep life_expectancy merged 
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge")
```
```{r}
## way1_full code: seperate and then spread
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge") %>%
  spread("variable_name",value)
```
4_2: method 2 for tyding data (less efficient):
```{r}
## way2_1: split the variable to two different ones, NA(empty)
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right")
```
```{r}
## way2_2: seperate and then unite
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_")
```
```{r}
# way2_full code for tidying data (way2: using unite)
dat %>% 
  separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_") %>%
  spread(variable_name,value) %>%
  rename(fertility=fertility_NA)
```

### Exercise1 (Reshaping Data)
For the data names times.csv, tidy the data? 
and then return them to the wide data!
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times.csv")
x <- read_csv(filename)

## tidying data
tidy_data1 <- x %>% gather(year,time,'2015':'2017')

## converting to wide data again
tidy_data1 %>% spread(year,time)
# it will create new columns for every year and spread the time values over those cells
```

### Exercise 2: 
Suppose we have the US_disease data in the work directory, tydy the data in which all disease are put in one column.
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"US_disease.csv")
y <- read_csv(filename)

## tidying data:
tidy_data2 <- y %>% gather(key=disease,value,'HepatitisA':'Rubella')
```

### exercise 3: tidy data that population and total be in different columns? and change the name of column to population and total
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"Population.csv")
z <- read_csv(filename)

## tidying data:
tidy_data3 <- z %>% spread(key=var,value=people)
```
### Exercise 4: for the data of times2.csv in the working directory, in the best way tidy the data:
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times2.csv")
x4 <- read_csv(filename)

## tidying data
x4 %>% gather(key="key",value="value",-age_group) %>%
    separate(key,c("year","variable_name"), sep="_") %>%
  spread(variable_name,value)
```

### Exercise 5: tidy the dataset named basketbal with different columns for varaiables:
```{r}
## Import and read data:
path <- getwd()
filename <- file.path(path,"basketball.csv")
Q <- read_csv(filename)

## tidying data
Q %>%
  separate(key,c("name","variable_name"), sep="_",extra="merge") %>%
  spread(variable_name,value)
```

### Exercise 6: Consider dataset co2 which comes with basic R. 
This dataset is not tidy. becuase as seen, month is a variable and it should be in a column. also there are multiple observations in each wow. each observation should be different from another one. 
```{r}
## co2 concentration dataset:
library(tidyverse)
library(dslabs)
co2

co2_wide <- data.frame(matrix(co2,ncol=12,byrow=TRUE)) %>%
  setNames(1:12) %>% mutate(year=as.character(1959:1997))
co2_wide 

co2_tidy <- gather(co2_wide,month,co2,-year)
co2_tidy

co2_tidy %>% ggplot(aes(as.numeric(month),co2,color=year)) + geom_line()
```

### Exercise 7: for the data of admission on the dslabs package: 
```{r}
## tidy data which has one row for each major:
library(dslabs)
data(admissions)
head(admissions)

dat <- admissions %>% select(-applicants)
dat

dat %>% spread("gender",admitted)
```
```{r}
## using admission dataset, generate tmp which has major, gender, key and value as columns. 

tmp <- gather(admissions, key, value, admitted:applicants)
tmp

## create a column from joining gender and key:
tmp2 <- unite(tmp,column_name,c(key,gender))
tmp2
```

## Key points: combining tables
- The join functions in the dplyr package combine two tables such that matching rows are together.
- left_join() only keeps rows that have information in the first table.
- right_join() only keeps rows that have information in the second table.
- inner_join() only keeps rows that have information in both tables.
- full_join() keeps all rows from both tables.
- semi_join() keeps the part of first table for which we have information in the second.
- anti_join() keeps the elements of the first table for which there is no information in the second.

```{r}
## joining tables
library(tidyverse)
library(ggrepel)
library(dslabs)
ds_theme_set()

# importing murders data
data(murders)
head(murders)

#importing US election results
data(polls_us_election_2016)
head(results_us_election_2016)

#check whether two columns of state in the tables are identical to be joined or not?
identical(murders$state,results_us_election_2016$state)
```
```{r}
## joining two tables by left_joint:
tab <- left_join(murders,results_us_election_2016,by="state")
head(tab)
```
```{r}
## plotting US population vs. electral votes
tab %>% ggplot(aes(population,electoral_votes, label=abb)) +
  geom_point() +
  geom_text_repel() +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="log2") +
  geom_smooth(method="lm",se=FALSE)
```
```{r}
## joing two tables in which state contained in two tables are different
tab1 <- slice(murders,1:6) %>% select(state,population)
tab1

tab2 <- slice(results_us_election_2016,c(1,14,22,27,44:45)) %>%
  select(state,electoral_votes)
tab2
```
```{r}
#different ways of using left_joint:
left_join(tab1,tab2) #it will start from left (tab1)
tab1 %>% left_join(tab2) #it will start from left (tab1)
tab1 %>% right_join(tab2) #it will start from right (tab2)
inner_join(tab1,tab2) 
full_join(tab1,tab2) #it works as union function
semi_join(tab1,tab2) #it does not add the column from second table
anti_join(tab1,tab2) #it will keep the informaton of first table that they do not exist in the second one
```

## Key points: Binding
- Unlike the join functions, the binding functions do not try to match by a variable, but rather just combine datasets.

- bind_cols() binds two objects by making them columns in a tibble. The R-base function cbind() binds columns but makes a data frame or matrix instead.

- The bind_rows() function is similar but binds rows instead of columns. The R-base function rbind() binds rows but makes a data frame or matrix instead.

```{r}
## creating a dataset of numbers
bind_cols(a=1:3,b=4:6)
cbind(a=1:3,b=4:6) #it will create matrix and ...
```
```{r}
tab <- left_join(murders,results_us_election_2016,by="state")

tab1 <- tab[, 1:3]
tab2 <- tab[, 4:6]
tab3 <- tab[, 7:9]
new_tab <- bind_cols(tab1,tab2,tab3)
head(new_tab)
```
```{r}
tab1 <- tab[1:2,]
tab2 <- tab[3:4,]
bind_rows(tab1,tab2)
```

## Key points:set operators
- By default, the set operators in R-base work on vectors. If tidyverse/dplyr are loaded, they also work on data frames.

- You can take intersections of vectors using intersect(). This returns the elements common to both sets.

- You can take the union of vectors using union(). This returns the elements that are in either set.

- The set difference between a first and second argument can be obtained with setdiff(). Note that this function is not symmetric.

- The function set_equal() tells us if two sets are the same, regardless of the order of elements.

```{r}
## Intersect for vectors:
intersect(1:10,6:18)
intersect(c("a","b","c"),c("b","c","d"))
```
```{r}
## Intersect for data frames:
tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
intersect(tab1,tab2)
```
```{r}
## Union for vectors and data frames:
union(1:10,6:18)
union(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
union(tab1,tab2)
```
```{r}
## setdiff function 
setdiff(1:10,6:18) #it is not symmetric
setdiff(6:18,1:10)
setdiff(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setdiff(tab1,tab2)
```
```{r}
## setequal function
setequal(1:5,1:6)
setequal(1:5,5:1)

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setequal(tab1,tab2)
```

### Exercise 1: 
install Lahman library which is related to US profesional baseball. and load following datases: Batting, Master, Salaries, and AwardsPlayers tables.

Considering Batting dataset:
```{r}
#filter Batting dataset to define top as the top 10 home run (HR) hitters in 2016
library(Lahman)
#data(Batting)
top <- Batting %>% 
  filter(yearID == 2016) %>%
  arrange(desc(HR)) %>%    # arrange by descending HR count
  slice(1:10)    # take entries 1-10

top %>% as_tibble()
```
considering Master dataset:
```{r}
## considering Master dataset:
Master %>% as_tibble() #info about all players
```
Joining masters and Batting:
```{r}
# using differnt functions, show a final table including: player ID, first name, last name, and number of HR for the top 10 players
top_names <- top %>% left_join(Master) %>% select(playerID,nameFirst,nameLast,HR)
top_names
```
considering salaries dataframe and joing with top_names:
```{r}
#filter this data to year of 2016, and add a salary column to top_names and names the resulting data frame as top_salary.
library(Lahman)
#head(Salaries)
top_salaries <- Salaries %>% filter(yearID=="2016") %>%
  right_join(top_names) %>%
  select(nameFirst, nameLast, teamID, HR, salary)
top_salaries
```
considering AwardPlayers dataset:
```{r}
## considering AwardPlayers dataframe:
library(Lahman)
Award_players_2016 <- AwardsPlayers %>% filter(yearID=="2016")

## the number of top 10 players who won at least one award in 2016
length(intersect(Award_players_2016$playerID, top_names$playerID))
semi_join(top_names,Award_players_2016)

## the number of players who won an award but were not on top home hit runners in 2016
length(setdiff(Award_players_2016$playerID,top_names$playerID))
```

