---
title: "Data_wrangling"
author: "Elham Sharifin, this course is taken from Edx data wrangling course. all the key points exactly the same of the course. I solved the questions myself!"
date: "4/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Key points: Introduction to wrnagling:
- The first step in data analysis is importing, tidying and cleaning the data. This is the process of data wrangling.

- Data analysis, for example checking correlations or creating visualizations, are done AFTER wrangling in which the data will be processed into a tidy format.

- In this course, we cover several common steps of the data wrangling process: tidying data, string processing, html parsing, working with dates and times, and text mining.

## Key points: Importing dat
- Many datasets are stored in spreadsheets. A spreadsheet is essentially a file version of a data frame with rows and columns.

- Spreadsheets have rows separated by returns and columns separated by a delimiter. The most common delimiters are comma, semicolon, white space and tab.

- Many spreadsheets are raw text files and can be read with any basic text editor. However, some formats are proprietary and cannot be read with a text editor, such as Microsoft Excel files (.xls).

- Most import functions assume that the first row of a spreadsheet file is a header with column names. To know if the file has a header, it helps to look at the file with a text editor before trying to import it.

## Key points: Paths and working directories:
- The working directory is where R looks for files and saves files by default.

- See your working directory with getwd(). Change your working directory with setwd().

- We suggest you create a directory for each project and keep your raw data inside that directory.

- Use the file.path() function to generate a full path from a relative path and a file name. Use file.path() instead of paste() because file.path() is aware of your operating system and will use the correct slashes to navigate your machine.

- The file.copy() function copies a file to a new path.
```{r}
#shows your working directory
getwd() 
```
```{r}
#changing the working directory
#setwd()
```
```{r}
# it shows the path of raw data inside the dslabs package and list files 
path <- system.file("extdata",package = "dslabs")
path 
list.files(path)
```
```{r}
# it will copy file from dslabs package to your working directory
filename <- "murders.csv"
fullpath <- file.path(path,filename)
file.copy(fullpath,getwd())
```
```{r}
#it shows if file exist in your working directory or not?
file.exists(filename)
```
```{r}
# copying the data murder.csv to an existing folder named data
getwd()
filename <- "murders.csv"
path <- system.file("extdata",package = "dslabs")
```
```{r}

# there are differnt ways for copying murders into data folder
## way1:
setwd("data")
file.copy(file.path(path, filename), getwd()) 
## way2:
file.copy(file.path(path, "murders.csv"), file.path(getwd(), "data"))
## way3:
file.location <- file.path(system.file("extdata", package = "dslabs"), "murders.csv")
file.destination <- file.path(getwd(), "data")
file.copy(file.location, file.destination) 

#way4: it does not work. it copies it into the parent directory
file.copy(file.path(path, "murders.csv"), getwd()) 
```

## Key points:The readr and readxl Packages
- readr is the tidyverse library that includes functions for reading data stored in text file spreadsheets into R. Functions in the package include:
read_csv(): comma seperated values, csv format
read_tsv(): tab delimited seperated values, tsv format
read_delim():general text file format,must define delimiter,txt format
read.csv2(): semicolon seperated values, csv format
read.table():white space seperated values, txt format
These differ by the delimiter they use to split columns.


- The readxl package provides functions to read Microsoft Excel formatted files.
read.excel: auto detect format. xlx, and xlsx formats
read.xls: original format (xls)
read.xlsx: new format, xlsx

- The excel_sheets() function gives the names of the sheets in the Excel file. These names are passed to the sheet argument for the readxl functions read_excel(), read_xls() and read_xlsx().

- The read_lines() function shows the first few lines of a file in R.

```{r}
library(dslabs)
library(tidyverse)    # includes readr
library(readxl)
```
```{r}
#it will investigate the first three lines
read_lines("murders.csv",n_max=3)
```
```{r}
#read files in csv format
dat <- read_csv(filename) #fiename from previous part
```
```{r}
# read file using fullpath
dat <- read_csv(fullpath) 
```
```{r}
head(dat)  #if we run in R console: we can see that file is a tibble
```
```{r}
#example: 
path <- system.file("extdata",package = "dslabs")
files <- list.files(path)
files

filename <- "murders.csv"
filename1 <- "life-expectancy-and-fertility-two-countries-example.csv"
filename2 <- "fertility-two-countries-example.csv"
dat <- read.csv(file.path(path,filename))
dat1 <- read.csv(file.path(path,filename1))
dat2 <- read.csv(file.path(path,filename2))

## excel files: suppose we have an excel file names times and the second sheet named 2016. we can read the second sheet with the following methos:
#times_2016 <- read_excel("times.xlsx", sheet = 2) 
#times_2016 <- read_excel("times.xlsx", sheet = "2016") 
```

## Key point: Importing Data Using R-base Functions
R-base import functions (read.csv(), read.table(), read.delim()) are different with read_... functions. R-base functions generate data frames rather than tibbles and character variables are converted to factors. This can be avoided by setting the argument stringsAsFactors=FALSE.
```{r}
filename <- "murders.csv"
dat2 <- read.csv(filename)
class(dat2)  #difference 1: we have data.frame not tibble
class(dat2$region) #character variables are converted to factors
```
```{r}
#converting to factors can be prevented by:
dat3 <- read.csv(filename,stringsAsFactors=FALSE)
class(dat3$region)
```

## Key points: Downloading Files from the Internet
- The read_csv() function and other import functions can read a URL directly.

- If there are no variable names in the first row fo a dataset, we have to add col_names=FALSE to skip putting the first row as header

- If you want to have a local copy of the file, you can use download.file().

- tempdir() creates a directory with a name that is very unlikely not to be unique.

- tempfile() creates a character string that is likely to be a unique filename.
```{r}
# reading data from internet
url <- "https://raw.githubusercontent.com/rafalab/dslabs/master/inst/extdata/murders.csv"
dat <- read_csv(url)
download.file(url,"murders.csv") #downloading file on your computer
tempfile() 
tmp_filename <- tempfile() #give a temporary name
download.file(url,tmp_filename)  #download it
file.remove(tmp_filename) #remove the temporary file
```
### Exercise: importing data
```{r}
library(tidyverse)
library(readr)

# import the file in the following url: http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data
url <- "http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
dat <- read_csv(url,col_names=FALSE) #very important, bcd there is no header for this data
ncol(dat)
nrow(dat)
```

## Key points: Tidy Data:
In tidy data, each row represents an observation and each column represents a different variable. very important!!!

In wide data, 1)each row includes several observations and 2)one of the variables is stored in the header.

```{r}
# Fertility data (example of tidy data)
library(tidyverse)
library(dslabs)
data(gapminder)
```
```{r}
# creating and investigating a tidy data frame
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
#plotting fertility vs. year
tidy_data %>%
  filter(!is.na(fertility),!is.na(year)) %>%
  ggplot(aes(year,fertility, color=country)) +
  geom_point()
```
```{r}
# import and investigate the original Gapminder data in wide format
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"fertility-two-countries-example.csv")
filename
file.copy(file.path(path, "fertility-two-countries-example.csv"), file.path(getwd(), "data"))
wide_data <- read_csv(filename) #same info but different format
select(wide_data, country, `1960`:`1967`)
```
 
## Key points: Reshaping data
- The tidyr package includes several functions that are useful for tidying data.

- The gather() function converts wide data into tidy data. gather takes 4 arguments: (1) the data, (2) the name of the key column, (3) the name of the value column, and optionally (4) the names of any columns not to gather

- The spread() function converts tidy data to wide data.

```{r}
## the original wide data
library(tidyverse) 
path <- system.file("extdata", package="dslabs")
filename <- file.path(path,  "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
```
```{r}
## tidy data from dslab package
tidy_data <- gapminder %>%
  filter(country %in% c("South Korea","Germany")) %>%
  select(country,year,fertility)
head(tidy_data)
```
```{r}
## gather wide data to make new tidy data (way 1)
new_tidy_data <- wide_data %>%
  gather(year,fertility,'1960':'2015')
# This code will gather the years from 1960 to 2015 into a single column and create a single column called “fertility” that contains the fetrility rate for each country and each year.
head(new_tidy_data)
```
```{r}
## gather all columns except country (way 2)
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country)
head(new_tidy_data)
```
```{r}
class(tidy_data$year)
class(new_tidy_data$year)
# the gather function assumes that column name are charactor and we need to convert the column to numbers!
```
```{r}
## convert gathered column names to numeric:
new_tidy_data <- wide_data %>%
  gather(year,fertility,-country,convert=TRUE)
head(new_tidy_data)

class(new_tidy_data$year)
```
```{r}
## now that the data are tidy, plotting
new_tidy_data %>%
  ggplot(aes(year,fertility,color=country)) +
  geom_point()
```
```{r}
## spread tidy data to generate wide data
new_wide_data <- new_tidy_data %>%
  spread(year,fertility)
select(new_wide_data, country, '1960':'1967')

```

## Key points: Separate and Unite
- The separate() function splits one column into two or more columns at a specified character that separates the variables. It has 3 argumnets: 1- the name of column to be seperated 2- the name to be used for the new column 3- charactor that seperates the variables

- When there is an extra separation in some of the entries, use fill="right" to pad missing values with NAs, or use extra="merge" to keep extra elements together.

- The unite() function combines two columns and adds a separating character.

1_Importing data:
```{r}
## Import data:
path <- system.file("extdata",package = "dslabs")
list.files(path)
filename <- file.path(path,"life-expectancy-and-fertility-two-countries-example.csv")
raw_data <- read_csv(filename)
select(raw_data,1:5)
```
2_gathering:
```{r}
## gather all columns but country
dat <- raw_data %>% gather(key,value,-country)
head(dat)
dat$key[1:5]
```
3_seperating:
```{r}
## seperate on underscores
dat %>% separate(key,c("year","variable_name"),"-")
dat %>% separate(key,c("year","variable_name"))
#error: it will seperate life_expectancy to two different parts and show only the first one
```
4_1: method 1 for tyding data:
```{r}
## way1_1: split on first underscore but keep life_expectancy merged 
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge")
```
```{r}
## way1_full code: seperate and then spread
dat %>% 
  separate(key,c("year","variable_name"), sep="_",extra="merge") %>%
  spread("variable_name",value)
```
4_2: method 2 for tyding data (less efficient):
```{r}
## way2_1: split the variable to two different ones, NA(empty)
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right")
```
```{r}
## way2_2: seperate and then unite
dat %>% separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_")
```
```{r}
# way2_full code for tidying data (way2: using unite)
dat %>% 
  separate(key,c("year","first_variable_name","second_variable_name"),fill = "right") %>%
  unite(variable_name,"first_variable_name","second_variable_name",sep="_") %>%
  spread(variable_name,value) %>%
  rename(fertility=fertility_NA)
```

### Exercise1 (Reshaping Data)
For the data names times.csv, tidy the data? 
and then return them to the wide data!
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times.csv")
x <- read_csv(filename)

## tidying data
tidy_data1 <- x %>% gather(year,time,'2015':'2017')

## converting to wide data again
tidy_data1 %>% spread(year,time)
# it will create new columns for every year and spread the time values over those cells
```

### Exercise 2: 
Suppose we have the US_disease data in the work directory, tydy the data in which all disease are put in one column.
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"US_disease.csv")
y <- read_csv(filename)

## tidying data:
tidy_data2 <- y %>% gather(key=disease,value,'HepatitisA':'Rubella')
```

### exercise 3: tidy data that population and total be in different columns? and change the name of column to population and total
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"Population.csv")
z <- read_csv(filename)

## tidying data:
tidy_data3 <- z %>% spread(key=var,value=people)
```
### Exercise 4: for the data of times2.csv in the working directory, in the best way tidy the data:
```{r}
## Import and read data:
path <- getwd()
list.files(path)
filename <- file.path(path,"times2.csv")
x4 <- read_csv(filename)

## tidying data
x4 %>% gather(key="key",value="value",-age_group) %>%
    separate(key,c("year","variable_name"), sep="_") %>%
  spread(variable_name,value)
```

### Exercise 5: tidy the dataset named basketbal with different columns for varaiables:
```{r}
## Import and read data:
path <- getwd()
filename <- file.path(path,"basketball.csv")
Q <- read_csv(filename)

## tidying data
Q %>%
  separate(key,c("name","variable_name"), sep="_",extra="merge") %>%
  spread(variable_name,value)
```

### Exercise 6: Consider dataset co2 which comes with basic R. 
This dataset is not tidy. becuase as seen, month is a variable and it should be in a column. also there are multiple observations in each wow. each observation should be different from another one. 
```{r}
## co2 concentration dataset:
library(tidyverse)
library(dslabs)
co2

co2_wide <- data.frame(matrix(co2,ncol=12,byrow=TRUE)) %>%
  setNames(1:12) %>% mutate(year=as.character(1959:1997))
co2_wide 

co2_tidy <- gather(co2_wide,month,co2,-year)
co2_tidy

co2_tidy %>% ggplot(aes(as.numeric(month),co2,color=year)) + geom_line()
```

### Exercise 7: for the data of admission on the dslabs package: 
```{r}
## tidy data which has one row for each major:
library(dslabs)
data(admissions)
head(admissions)

dat <- admissions %>% select(-applicants)
dat

dat %>% spread("gender",admitted)
```
```{r}
## using admission dataset, generate tmp which has major, gender, key and value as columns. 

tmp <- gather(admissions, key, value, admitted:applicants)
tmp

## create a column from joining gender and key:
tmp2 <- unite(tmp,column_name,c(key,gender))
tmp2
```

## Key points: combining tables
- The join functions in the dplyr package combine two tables such that matching rows are together.
- left_join() only keeps rows that have information in the first table.
- right_join() only keeps rows that have information in the second table.
- inner_join() only keeps rows that have information in both tables.
- full_join() keeps all rows from both tables.
- semi_join() keeps the part of first table for which we have information in the second.
- anti_join() keeps the elements of the first table for which there is no information in the second.

```{r}
## joining tables
library(tidyverse)
library(ggrepel)
library(dslabs)
ds_theme_set()

# importing murders data
data(murders)
head(murders)

#importing US election results
data(polls_us_election_2016)
head(results_us_election_2016)

#check whether two columns of state in the tables are identical to be joined or not?
identical(murders$state,results_us_election_2016$state)
```
```{r}
## joining two tables by left_joint:
tab <- left_join(murders,results_us_election_2016,by="state")
head(tab)
```
```{r}
## plotting US population vs. electral votes
tab %>% ggplot(aes(population,electoral_votes, label=abb)) +
  geom_point() +
  geom_text_repel() +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="log2") +
  geom_smooth(method="lm",se=FALSE)
```
```{r}
## joing two tables in which state contained in two tables are different
tab1 <- slice(murders,1:6) %>% select(state,population)
tab1

tab2 <- slice(results_us_election_2016,c(1,14,22,27,44:45)) %>%
  select(state,electoral_votes)
tab2
```
```{r}
#different ways of using left_joint:
left_join(tab1,tab2) #it will start from left (tab1)
tab1 %>% left_join(tab2) #it will start from left (tab1)
tab1 %>% right_join(tab2) #it will start from right (tab2)
inner_join(tab1,tab2) 
full_join(tab1,tab2) #it works as union function
semi_join(tab1,tab2) #it does not add the column from second table
anti_join(tab1,tab2) #it will keep the informaton of first table that they do not exist in the second one
```

## Key points: Binding
- Unlike the join functions, the binding functions do not try to match by a variable, but rather just combine datasets.

- bind_cols() binds two objects by making them columns in a tibble. The R-base function cbind() binds columns but makes a data frame or matrix instead.

- The bind_rows() function is similar but binds rows instead of columns. The R-base function rbind() binds rows but makes a data frame or matrix instead.

```{r}
## creating a dataset of numbers
bind_cols(a=1:3,b=4:6)
cbind(a=1:3,b=4:6) #it will create matrix and ...
```
```{r}
tab <- left_join(murders,results_us_election_2016,by="state")

tab1 <- tab[, 1:3]
tab2 <- tab[, 4:6]
tab3 <- tab[, 7:9]
new_tab <- bind_cols(tab1,tab2,tab3)
head(new_tab)
```
```{r}
tab1 <- tab[1:2,]
tab2 <- tab[3:4,]
bind_rows(tab1,tab2)
```

## Key points:set operators
- By default, the set operators in R-base work on vectors. If tidyverse/dplyr are loaded, they also work on data frames.

- You can take intersections of vectors using intersect(). This returns the elements common to both sets.

- You can take the union of vectors using union(). This returns the elements that are in either set.

- The set difference between a first and second argument can be obtained with setdiff(). Note that this function is not symmetric.

- The function set_equal() tells us if two sets are the same, regardless of the order of elements.

```{r}
## Intersect for vectors:
intersect(1:10,6:18)
intersect(c("a","b","c"),c("b","c","d"))
```
```{r}
## Intersect for data frames:
tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
intersect(tab1,tab2)
```
```{r}
## Union for vectors and data frames:
union(1:10,6:18)
union(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
union(tab1,tab2)
```
```{r}
## setdiff function 
setdiff(1:10,6:18) #it is not symmetric
setdiff(6:18,1:10)
setdiff(c("a","b","c"),c("b","c","d"))

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setdiff(tab1,tab2)
```
```{r}
## setequal function
setequal(1:5,1:6)
setequal(1:5,5:1)

tab <- left_join(murders,results_us_election_2016,by="state")
tab1 <- tab[1:5,]
tab2 <- tab[3:7,]
setequal(tab1,tab2)
```

### Exercise 1: 
install Lahman library which is related to US profesional baseball. and load following datases: Batting, Master, Salaries, and AwardsPlayers tables.

Considering Batting dataset:
```{r}
#filter Batting dataset to define top as the top 10 home run (HR) hitters in 2016
library(Lahman)
#data(Batting)
top <- Batting %>% 
  filter(yearID == 2016) %>%
  arrange(desc(HR)) %>%    # arrange by descending HR count
  slice(1:10)    # take entries 1-10

top %>% as_tibble()
```
considering Master dataset:
```{r}
## considering Master dataset:
Master %>% as_tibble() #info about all players
```
Joining masters and Batting:
```{r}
# using differnt functions, show a final table including: player ID, first name, last name, and number of HR for the top 10 players
top_names <- top %>% left_join(Master) %>% select(playerID,nameFirst,nameLast,HR)
top_names
```
considering salaries dataframe and joing with top_names:
```{r}
#filter this data to year of 2016, and add a salary column to top_names and names the resulting data frame as top_salary.
library(Lahman)
#head(Salaries)
top_salaries <- Salaries %>% filter(yearID=="2016") %>%
  right_join(top_names) %>%
  select(nameFirst, nameLast, teamID, HR, salary)
top_salaries
```
considering AwardPlayers dataset:
```{r}
## considering AwardPlayers dataframe:
library(Lahman)
Award_players_2016 <- AwardsPlayers %>% filter(yearID=="2016")

## the number of top 10 players who won at least one award in 2016
length(intersect(Award_players_2016$playerID, top_names$playerID))
semi_join(top_names,Award_players_2016)

## the number of players who won an award but were not on top home hit runners in 2016
length(setdiff(Award_players_2016$playerID,top_names$playerID))
```

## Key points: Web Scrapping
- Web scraping is extracting data from a website.

- The rvest web harvesting package includes functions to extract nodes (<>) of an HTML document: html_nodes() extracts all nodes of different types, and html_node() extracts the first node.

- html_table() converts an HTML table to a data frame.
### importing webpage (murder) to R:
```{r}
# importing a webpage (murder) to R:
library(rvest)
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
h <- read_html(url)
class(h)
h  # we dont see very much!

tab <- h %>% html_nodes("table")

tab <- tab[[2]]

tab <- tab %>% html_table
class(tab)

tab <- tab %>% setNames(c("state", "population", "total", "murders", "gun_murders", "gun_ownership", "total_rate", "murder_rate", "gun_murder_rate"))
head(tab)
```
### importing webpage (corona virus) to R:
```{r}
# importing a webpage (corona virus statistics) to R:
library(rvest)
url <- "https://www.worldometers.info/coronavirus/"
h_corona <- read_html(url)
class(h_corona)

tab_corona <- h_corona %>% html_nodes("table")
tab_corona <- tab_corona[[2]]

tab_corona <- tab_corona%>% html_table
class(tab_corona)

```

## CSS Selector:
Here, we want to extract the recipe name, total preparation time, and list of ingredients from this guacamole recipe (https://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609). looking at the source page, it is very complex to determine the selector. SelectorGadget is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables, we highly recommend you install it. 
By installing SelectBudget, you can undestand the selectors:
```{r}
h <- read_html("https://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()

guacamole <- list(recipe,prep_time,ingredients)
guacamole

# creating a function from this recipe
get_recipe <- function(url){
  h <- read_html(url)
  recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
return(list(recipe,prep_time,ingredients))
}

# example of using the function get_recipe
get_recipe("https://www.foodnetwork.com/recipes/food-network-kitchen/pancakes-recipe-1913844")
```

There are several other powerful tools provided by rvest. For example, the functions html_form(), set_values(), and submit_form() permit you to query a webpage from R

### Exercise: Major League Baseballs Payrolls
use the following URL to access data related to Major League Baseball payrolls:
https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm
```{r}
library(rvest)
library(tidyverse)
h <- read_html("https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm")
nodes <- html_nodes(h,"table")
class(nodes) #html_nodes returns a list of objects of class xml_nodes

html_text(nodes[[8]]) #the content of each object can be seen by htm_text

html_table(nodes[[8]]) #convert the nodes (objects) to data.frame

## convert the first 4 tables to data.frame:
sapply(nodes[1:4],html_table)

## for the last three componenets of nodes:
html_table(nodes[[length(nodes)]])
html_table(nodes[[length(nodes)-1]])
html_table(nodes[[length(nodes)-2]])
```
```{r}
## for the nodes 9, 18: change table in which remove row1, and change the the column 1 of first table, and change the column names to Team, Payroll, and Average
###method 1 by Elham:
tab1 <- html_table(nodes[[9]]) %>% select(Team=X2,Payroll=X3,Average=X4) %>% slice(2:31)
head(tab1)
tab2 <- html_table(nodes[[18]]) %>% select(Team=X1,Payroll=X2,Average=X3) %>% slice(2:31)
head(tab2)
join_table <- full_join(tab1,tab2,by="Team")

### method 2 by Edx:
tab_1 <- html_table(nodes[[9]]) 
tab_2 <- html_table(nodes[[18]])

  #removing extra row and columns
tab_1 <- tab_1[-1,-1] #removing one row and one column from data frame
tab_2 <- tab_2[-1,]  #removing one raw from data frame.

  #changing the name of columns
column_name <- c("Team","Payroll","Average")
names(tab_1) <- column_name 
names(tab_2) <- column_name

full_join(tab1,tab2,by="Team")
```

### Exercise: 
following wikipedia page is related to polls of UK to leave the Europe Union in 2016. one of the tables show the results of all polls. 
https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054

```{r}
library(tidyverse)
library(rvest)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"

h <- read_html(url)
tab <- html_nodes(h,"table")
html_table(tab[[5]],fill=TRUE)

## what is the table number of the table "Date Conducted"?
html_table(tab[[5]],fill=TRUE) %>% names()
```


